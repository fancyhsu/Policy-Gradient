{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your model path\n",
    "model_path = \"./saved_model/policy_gradient_0\"\n",
    "# model_path = \"./saved_model/DL_comp4_15_model\"\n",
    "\n",
    "model_path = \"DL_comp4_15_model\"\n",
    "\n",
    "# set it True if your model returns multiple values\n",
    "multiple_return_values = False\n",
    "\n",
    "# set visible GPU\n",
    "gpu_number = 0\n",
    "\n",
    "# print out more information\n",
    "verbose = False\n",
    "\n",
    "# public seed is 2021\n",
    "seed = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_number], 'GPU')\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"  # this line disable pop-out window\n",
    "from ple.games.flappybird import FlappyBird\n",
    "from ple import PLE\n",
    "\n",
    "game = FlappyBird()\n",
    "env = PLE(game, fps=30, display_screen=False, rng=seed)  # game environment interface\n",
    "env.reset_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TA_state():\n",
    "    state = copy.deepcopy(game.getGameState())\n",
    "    \n",
    "    state['next_next_pipe_bottom_y'] -= state['player_y']\n",
    "    state['next_next_pipe_top_y'] -= state['player_y']\n",
    "    state['next_pipe_bottom_y'] -= state['player_y']\n",
    "    state['next_pipe_top_y'] -= state['player_y']\n",
    "    relative_state = list(state.values())\n",
    "\n",
    "\n",
    "    # return the state in tensor type, with batch dimension\n",
    "    relative_state = tf.convert_to_tensor(relative_state, dtype=tf.float32)\n",
    "    relative_state = tf.expand_dims(relative_state, axis=0)\n",
    "    \n",
    "    return relative_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average alive time: 207.07,\n",
      "average episode reward: 3.94\n",
      "show your result https://docs.google.com/spreadsheets/d/1QHNmes31XdUSsG2K9U7cgTggeGfiMgADvrJJsETjbxM\n"
     ]
    }
   ],
   "source": [
    "alive_times = []\n",
    "episode_rewards = []\n",
    "\n",
    "for test_num in range(1, 101):\n",
    "    alive_time = 1\n",
    "    episode_reward = 0\n",
    "    env.reset_game()\n",
    "\n",
    "    while not env.game_over():\n",
    "        state = TA_state()\n",
    "\n",
    "        # Your model should return action probabilities\n",
    "        # In other words, the last layer of your model should be Softmax\n",
    "        \n",
    "        if not multiple_return_values:\n",
    "            action_prob = model(state)\n",
    "        else:\n",
    "            action_prob = model(state)[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"test num: {test_num}, frame: {alive_time}, action probs: {action_prob}\")\n",
    "            \n",
    "        action_idx = tf.argmax(action_prob, axis=1)[0]\n",
    "\n",
    "        reward = env.act(env.getActionSet()[action_idx])\n",
    "\n",
    "        alive_time += 1\n",
    "        episode_reward += reward\n",
    "        if episode_reward == 5: break\n",
    "        \n",
    "    alive_times.append(alive_time)\n",
    "    episode_rewards.append(episode_reward)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[{test_num}] alive: {alive_time}, episode reward: {episode_reward}\")\n",
    "    \n",
    "print(f\"average alive time: {np.mean(np.asarray(alive_times))},\\naverage episode reward: {np.mean(np.asarray(episode_rewards))}\\nshow your result https://docs.google.com/spreadsheets/d/1QHNmes31XdUSsG2K9U7cgTggeGfiMgADvrJJsETjbxM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
